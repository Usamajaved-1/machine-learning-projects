{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8042e5c1-e3c7-497f-9e38-d1b1471faed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e015019b-be86-4bfd-9eae-619b8f04a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,Dense,Flatten,MaxPooling2D #explain in register\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # used to genenrate image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20eb04a7-8f90-4502-b1fd-5f973e451267",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6357d86d-1b61-43e4-8b30-cd8462243df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(32,(3,3),input_shape = (64,64,3),activation=\"relu\")) \n",
    "# filter(32) mean how much we use for edges detection , kernel size(3,3) as we give in reg 3color\n",
    "# are in image ,input_shape = (64,64) mean size of our image  3 mean rgb(3colors) our image is \n",
    "# colorful ,acitivation i defined before \n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2))) # as it is we give \n",
    "cnn.add(Conv2D(32,(3,3),activation=\"relu\")) \n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2))) # we use two time explain in register \n",
    "# now our data is Flatten\n",
    "cnn.add(Flatten()) # now we create an ann network inside it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5cc8933-13ca-4c67-9299-3fd540a5b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64,activation=\"relu\")) # 64 is the no of nodes \n",
    "cnn.add(Dense(32,activation=\"relu\"))\n",
    "cnn.add(Dense(16,activation=\"relu\"))\n",
    "cnn.add(Dense(8,activation=\"relu\"))\n",
    "cnn.add(Dense(4,activation=\"relu\"))\n",
    "cnn.add(Dense(1,activation=\"sigmoid\")) # sigmoid bcz output is in binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44b19895-a8a8-464e-af89-4600b4ce0393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compile \n",
    "cnn.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17621068-7367-428b-9760-af2e1be649c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R c\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 253ms/step - loss: 0.6728 - val_loss: 0.7769\n",
      "Epoch 2/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 291ms/step - loss: 0.6371 - val_loss: 0.6088\n",
      "Epoch 3/15\n",
      "\u001b[1m 50/100\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - loss: 0.6089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R c\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - loss: 0.6074 - val_loss: 0.6319\n",
      "Epoch 4/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 192ms/step - loss: 0.6080 - val_loss: 0.6172\n",
      "Epoch 5/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 178ms/step - loss: 0.5566 - val_loss: 0.5436\n",
      "Epoch 6/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 0.5669 - val_loss: 0.5393\n",
      "Epoch 7/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - loss: 0.5508 - val_loss: 0.5383\n",
      "Epoch 8/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 156ms/step - loss: 0.5266 - val_loss: 0.5362\n",
      "Epoch 9/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - loss: 0.5461 - val_loss: 0.6016\n",
      "Epoch 10/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 161ms/step - loss: 0.5299 - val_loss: 0.5159\n",
      "Epoch 11/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 165ms/step - loss: 0.4881 - val_loss: 0.5248\n",
      "Epoch 12/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - loss: 0.5240 - val_loss: 0.5264\n",
      "Epoch 13/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 196ms/step - loss: 0.4927 - val_loss: 0.4965\n",
      "Epoch 14/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - loss: 0.4974 - val_loss: 0.5113\n",
      "Epoch 15/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - loss: 0.4817 - val_loss: 0.5238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22da4d91700>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this cod is from keras .python documentation than image preprocessing \n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\R c\\Desktop\\ws_cube_data_sciece\\dataset\\training_set\",# here we give the path of our training data \n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\R c\\Desktop\\ws_cube_data_sciece\\dataset\\test_set\", # here path of testing data \n",
    "        target_size=(64, 64), # change it to 64 bcz we above use 64 \n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(train_generator,steps_per_epoch=100,epochs=15,validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3373a2e6-c816-4c90-b079-91b8ef0c4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WE TEST OUR IMAGE \n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c838ea30-239d-46bc-911e-c46840bf4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(r\"C:\\Users\\R c\\Desktop\\ws_cube_data_sciece\\dataset\\single_prediction\\dog.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5038daef-0e34-4cd0-a066-eed5a1a024b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first we have to convert our image to array  \n",
    "img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "25199017-d9e2-4f40-b1a5-81cce63c56db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        ...,\n",
       "        [245., 245., 245.],\n",
       "        [245., 245., 245.],\n",
       "        [245., 245., 245.]],\n",
       "\n",
       "       [[239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        ...,\n",
       "        [245., 245., 245.],\n",
       "        [245., 245., 245.],\n",
       "        [244., 244., 244.]],\n",
       "\n",
       "       [[239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        ...,\n",
       "        [244., 244., 244.],\n",
       "        [244., 244., 244.],\n",
       "        [244., 244., 244.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[241., 217., 205.],\n",
       "        [243., 220., 206.],\n",
       "        [242., 219., 205.],\n",
       "        ...,\n",
       "        [226., 201., 181.],\n",
       "        [233., 205., 193.],\n",
       "        [232., 215., 197.]],\n",
       "\n",
       "       [[255., 236., 229.],\n",
       "        [251., 234., 227.],\n",
       "        [252., 235., 227.],\n",
       "        ...,\n",
       "        [219., 193., 178.],\n",
       "        [219., 193., 178.],\n",
       "        [216., 189., 172.]],\n",
       "\n",
       "       [[243., 230., 224.],\n",
       "        [250., 235., 228.],\n",
       "        [245., 232., 226.],\n",
       "        ...,\n",
       "        [203., 180., 164.],\n",
       "        [220., 198., 177.],\n",
       "        [225., 202., 186.]]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0c660d4-3a47-4dcd-8d34-2ed037d28d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05a120f9-0bb3-4fea-944e-cdb8dc472bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img,axis=0) # we have to flatten mean dimension change explain in reg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b6defda-8f23-4c40-a901-9c3183aecc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "p= cnn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12e3b80b-a183-46ed-85b1-1718228d240f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "646b00da-fc6d-4370-a7b1-0f9cda1f1e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "if p[0]<1: \n",
    "    print(\"cat\")\n",
    "else: \n",
    "    print(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50e863-5216-4d91-836b-568343b25eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally our prediction is good and accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514cea5-e30e-43b9-8d75-0f9ee94e8cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
